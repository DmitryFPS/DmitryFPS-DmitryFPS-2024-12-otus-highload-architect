# Учебный проект: Социальная сеть

Этот проект представляет собой учебное приложение социальной сети, разработанное с использованием современных
технологий. Весь стек технологий можно узнать в файле `pom.xml`.

---

## Как запустить приложение

### 1. Настройка системных переменных (Environment Variables)

Для корректной работы приложения необходимо настроить системные переменные:

1. Перейдите в **Edit Configurations**.
2. Выберите ваше приложение (**Application**).
3. Перейдите в **Modify options**.
4. Выберите **Environment Variables**.
5. Заполните переменные:

    - **JWT_EXPIRATION**: Срок действия токена (в секундах).  
      Пример: `86400` (24 часа).
    - **JWT_SECRET**: Секретный ключ для генерации JWT.  
      Пример: `+AVVLHD+9HxbBZYQmEnnuwisUGzW/m89H7i5FMkHEqE=`.  
      Вы можете использовать этот ключ или сгенерировать свой с помощью теста `SecretKeyGeneratorTest` (алгоритм
      HMAC-SHA256).
    - **PASSWORD_BD**: Пароль для подключения к базе данных.  
      Пример: `root`.
    - **USER_NAME_BD**: Имя пользователя для подключения к базе данных.  
      Пример: `root`.

---

### 2. Запуск Docker Compose

Запустите приложение с помощью Docker Compose:

```bash
docker compose up -d
```

Этот скрипт выполняет следующие действия:

- Поднимает **PostgreSQL** (база данных).
- Собирает приложение в Docker-контейнер (в разработке, контейнер может падать).
- Теперь запускаем приложение жмякаем run

---

## Работа с приложением через Postman

### 3. Получение JWT Token

Для получения токена выполните следующие шаги:

1. Отправьте POST-запрос на эндпоинт:  
   `POST http://localhost:8080/api/v1/login`
2. В теле запроса (Body -> raw -> JSON) укажите:
   ```json
   {
       "username": "ddd12@mail.ru",
       "password": "root"
   }
   ```
3. В ответе вы получите JWT Token.

---

### 4. Получение пользователя по ID

Для получения информации о пользователе выполните следующие шаги:

1. Отправьте GET-запрос на эндпоинт:  
   `GET http://localhost:8080/api/v1/user/{id}`
2. В разделе **Authorization** выберите тип авторизации **Bearer Token**.
3. Вставьте токен, полученный на предыдущем шаге.

---

### 5. Регистрация нового пользователя

Для регистрации нового пользователя выполните следующие шаги:

1. Отправьте POST-запрос на эндпоинт:  
   `POST http://localhost:8080/api/v1/user/register`
2. В теле запроса (Body -> raw -> JSON) укажите данные пользователя:
   ```json
   {
     "firstName": "Olya",
     "lastName": "Orlova",
     "birthDate": "1995-12-11T21:00:00.000+00:00",
     "gender": "FEMALE",
     "interests": ["It", "Moto", "Other"],
     "city": "Ulyanovsk",
     "email": "olya111@mail.ru",
     "password": "super",
     "role": ["USER", "ADMIN"]
   }
   ```
3. Токен для этого запроса не требуется.

---

### 6. Обновление Токена

Для обновления старого токена выполните следующие шаги:

1. Отправьте POST-запрос на эндпоинт:  
   `POST http://localhost:8080/api/v1/refresh`
2. В теле запроса (Body -> raw -> JSON) укажите данные пользователя:
   ```json
   {
     "refreshToken": ""
   }
   ```
3. В разделе **Authorization** выберите тип авторизации **Bearer Token**. Укажите тот же токен что и в Body

---

### 7. Logout

Для logout выполните следующие шаги:

1. Отправьте POST-запрос на эндпоинт:  
   `POST http://localhost:8080/api/v1/logout`
2. В теле запроса (Body -> raw -> JSON) укажите данные пользователя:
   ```json
   {
     "email": "ddd12@mail.ru"
   }
   ```

---

### 8. Postman-коллекция

Для удобства тестирования API в проекте доступна Postman-коллекция. Ее можно найти в директории `postman`.

---

## Структура проекта

- **`pom.xml`**: Файл конфигурации Maven, содержащий список зависимостей и используемых технологий.
- **`src/main/java`**: Исходный код приложения.
- **`src/test/java`**: Тесты для приложения.
- **`postman`**: Коллекция Postman для тестирования API.

---

## Технологии

- **Java**: Основной язык разработки.
- **Spring Boot**: Фреймворк для создания приложения.
- **PostgreSQL**: База данных.
- **Docker**: Контейнеризация приложения.
- **JWT (JSON Web Token)**: Аутентификация и авторизация.
- **Postman**: Тестирование API.

---

## Генерация 1_000_000 анкет

- Запускаем GenerateCSV будет сгенерированы 3 файла в /resources/migration
  users.csv, user_roles.csv, user_interests.csv
- Можно на уникальность проверить csv
    - sort users.csv | uniq -d
    - sort user_roles.csv | uniq -d
    - sort user_interests.csv | uniq -d
- Далее запускаем приложение и они сгенерирует начальные схемы
- Далее запускаем docker-compose.yml
- Заходим в контейнер docker exec -it CONTAINER ID bash
- Заходим в psql -h postgres -p 5432 -U root -d db (По просьбе вводим пароль от БД 'root')
- Проверяем что находимся там где нужно Пример одной схемы \dt public.users
- Выполняем быструю вставку больших объемов данных:
    - \copy users (first_name, last_name, birth_date, gender, email, password, is_active, city_id) FROM '
      /data/users.csv'
      WITH (FORMAT csv, HEADER);
    - \copy user_roles (user_id, role_id) FROM '/data/user_roles.csv' WITH (FORMAT csv, HEADER);
    - \copy user_interests (user_id, interest_id) FROM '/data/user_interests.csv' WITH (FORMAT csv, HEADER);
- Идем в БД и проверяем что все хорошо

## Проверка, что в файлах полное кол-во данных (IDEA почему то не всегда показывает больше 12 000 строк)

- wc -l users.csv
- wc -l user_interests.csv
- wc -l user_roles.csv

## Для нагрузочного тестирования поиска анкет по префиксу имени и фамилии (одновременно)

- Запрос в форме firstName LIKE ? and secondName LIKE ?
- Сортировать вывод по id анкеты
- GET /user/search?first_name=Конст&last_name=Оси

## Отчет по тестированию производительности запросов до и после добавления индексов

[Отчет: ](./src/main/java/ru/otus/orlov/docs/loadtestingreport/report.md)

---

# Репликация

[Отчет: ](src/main/java/ru/otus/orlov/docs/replication/report.md)

# Кэширование

# Полный отчет о нагрузке и расчете количества постов

## 1. Исходные данные:

• Количество запросов: 1000
• Пользователей на запрос: 1000
• Друзей у каждого пользователя: от 200 до 500
• Постов у каждого друга: от 5 до 10
• Кэш: вмещает 1000 постов, очищается каждую минуту
• Очередь RabbitMQ: используется для передачи данных из БД в Кэш и из Кэша в репозиторий

## 2. Расчет общего количества постов:

### Для каждого запроса:

• Количество пользователей: 1000
• Количество друзей у каждого пользователя: в среднем (200 + 500) / 2 = 350
• Количество постов у каждого друга: в среднем (5 + 10) / 2 = 7.5
• Общее количество постов для одного запроса:  `1000 пользователей × 350 друзей × 7.5 постов = 2,625,000 постов`

### Для 1000 запросов:

•   `1000 × 2,625,000 = 2,625,000,000 постов`

## 3. Нагрузка до кэширования:

• Среднее время выполнения запроса: 837 мс
• Минимальное время: 12 мс
• Максимальное время: 7648 мс
• Стандартное отклонение: 1554.28 мс
• Ошибки: 3.600%
• Пропускная способность: 57.20169 запросов в секунду
• Получено данных: 6258.67 KB/сек
• Отправлено данных: 20.33 KB/сек
• Средний размер ответа: 112040.1 байт

## 4. Нагрузка после кэширования:

• Среднее время выполнения запроса: 78 мс
• Минимальное время: 9 мс
• Максимальное время: 408 мс
• Стандартное отклонение: 70.06 мс
• Ошибки: 0.000%
• Пропускная способность: 125.37613 запросов в секунду
• Получено данных: 14228.23 KB/сек
• Отправлено данных: 44.57 KB/сек
• Средний размер ответа: 116208.0 байт

## 5. Анализ нагрузки:

### До кэширования:

Система испытывает значительную нагрузку:

• Среднее время выполнения запроса составляет 837 мс, что указывает на задержки в обработке данных.
• Максимальное время выполнения запроса достигает 7648 мс, что свидетельствует о наличии "тяжелых" запросов.
• Стандартное отклонение (1554.28 мс) указывает на высокую вариативность времени выполнения запросов.
• Уровень ошибок составляет 3.600%, что может быть связано с перегрузкой самой очереди RabbitMQ
(местами при высокой нагрузке не получается десериализовать данные).
• Пропускная способность составляет 57.20169 запросов в секунду, что является относительно низким показателем для такой
нагрузки.

### После кэширования:

Производительность системы значительно улучшилась:

• Среднее время выполнения запроса снизилось до 78 мс, что в 10.7 раз быстрее, чем до кэширования.
• Максимальное время выполнения запроса уменьшилось до 408 мс, что свидетельствует об эффективности кэширования.
• Стандартное отклонение снизилось до 70.06 мс, что указывает на стабильность работы системы.
• Уровень ошибок снизился до 0.000%, что подтверждает эффективность кэширования.
• Пропускная способность увеличилась до 125.37613 запросов в секунду, что более чем в 2 раза выше, чем до кэширования.
• Увеличился объем получаемых данных (14228.23 KB/сек), что связано с более быстрой обработкой запросов.

- Приложение так же можно запустить через контейнер и локально через среду IDEA
- (Локально то меняет хосты на localhost если через контейнер то меняем хосты на имена контейнеров)
- Так же для подтверждения, что данные в кэше есть и они валидны и их не более 1000 - есть контроллер с эндпоинтом для запроса в кэш